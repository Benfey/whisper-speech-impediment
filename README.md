# Speech Impediment Recognition with Whisper Fine-Tuning

This project helps you fine-tune OpenAI's Whisper model to better understand speech impediments, creating a personalized speech recognition model adapted to your specific speech patterns.

## Setup

1. Create and activate a virtual environment:

```bash
python -m venv env
# On Windows:
env\Scripts\activate
# On Unix/MacOS:
source env/bin/activate
```

2. Install dependencies:

```bash
pip install -r requirements.txt
```

## Data Collection Strategy

### Recording Guidelines

1. Record at least 50-100 short voice clips:

   - Each clip should be 15-30 seconds long
   - Record in a quiet environment
   - Use consistent audio volume
   - Speak naturally, don't try to "correct" your impediment

2. Include diverse speech samples:

   - Words/sounds you typically have difficulty with
   - Reading text passages
   - Casual conversation
   - Formal speech
   - Common phrases you use

3. Recording quality:
   - Use WAV format
   - Ensure clear audio without background noise
   - Maintain consistent distance from microphone
   - Use a good quality microphone if possible

### Transcription Guidelines

1. Create exact transcriptions:

   - Use standard spelling (not phonetic)
   - Write words as they should be, not as pronounced
   - Include punctuation where appropriate

2. Example:
   - If you say: "thoup and thalad"
   - Write in transcription: "soup and salad"

## Project Structure

```
data/
├── raw/                # Your original recordings and transcriptions
│   ├── recording1.wav  # Audio file with speech impediment
│   ├── recording1.txt  # Correct transcription of intended speech
│   ├── recording2.wav
│   ├── recording2.txt
│   └── ...
├── processed/          # Auto-generated by prepare_data.py
├── text/              # Auto-generated by prepare_data.py
└── audio_paths/       # Auto-generated by prepare_data.py
```

## File Requirements

1. Audio Files:

   - Format: WAV
   - Duration: 15-30 seconds
   - Location: data/raw/
   - Naming: Any name with .wav extension

2. Transcription Files:
   - Format: Plain text (.txt)
   - Same name as audio file (with .txt extension)
   - Contains correct intended speech
   - Location: Same directory as audio file
   - Example: If audio is "recording1.wav", transcription is "recording1.txt"

## Training Process

1. Prepare your dataset:

   ```bash
   python scripts/prepare_data.py
   ```

   This processes your audio files and creates necessary training files.

2. Start fine-tuning:
   ```bash
   python scripts/train.py
   ```
   The training process:
   - Uses the Whisper base model
   - Adapts to your speech patterns
   - Monitors improvement through Word Error Rate (WER)
   - Saves the best performing model

## Training Parameters

The model is configured for optimal learning of speech impediments:

- Base Model: whisper-base (better accuracy than tiny)
- Learning Rate: 1e-5 (for stable adaptation)
- Training Steps: 6000 (sufficient for pattern learning)
- Batch Size: 8 (balanced for memory/speed)
- Evaluation: Every 1000 steps
- Metric: Word Error Rate (WER)

## Testing Your Model

After training, test the model on new recordings:

```bash
python scripts/transcribe.py path/to/new_recording.wav
```

Compare transcriptions between:

- Original Whisper model
- Your fine-tuned model

## Tips for Best Results

1. Data Quality:

   - Ensure transcriptions are accurate
   - Include variety in speech content
   - Record in consistent conditions
   - Use clear audio quality

2. Training:

   - Monitor the WER metric
   - Let training complete all steps
   - Save models with best WER scores
   - Test with various speech samples

3. Iteration:
   - Test the model with new recordings
   - Add more training data if needed
   - Focus on problematic words/sounds
   - Fine-tune multiple times if necessary
